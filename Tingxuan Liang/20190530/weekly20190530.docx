â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
Time: from 26/05/2019 to 30/05/2019
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
	Read Paper
Landmark based localization in urban environment
åˆ›æ–°ç‚¹ï¼š
	è€ƒè™‘äº†åŸºäºgeo-referenceçš„è·¯æ ‡ç‚¹ï¼Œæå‡ºæ–°çš„ç‰¹å¾ç‚¹è·Ÿè¸ªå’ŒåŒ¹é…æ–¹å¼
	åœ¨ä½å§¿ä¼°è®¡æ—¶ï¼Œå°†å‚è€ƒä½ç½®è€ƒè™‘è¿›å»
	è€ƒè™‘äº†ä¼ æ„Ÿå™¨åœ¨æ±½è½¦ä¸Šçš„æ‘†æ”¾æ–¹å¼ï¼ˆ4ä¸ªç›¸æœºåœ¨è½¦ä¸Šï¼Œ2å‰2åï¼‰
	é‡‡ç”¨ä¸¤ç§geo-referenceï¼šç¬¬ä¸€ç§æ˜¯road marksï¼Œç¬¬äºŒç§æ˜¯road signsã€‚æœ€ååˆ†æç›¸æœºçš„ä¸ªæ•°åˆ†åˆ«æ˜¯2,3,4æ—¶ï¼Œä½¿ç”¨å…¶ä¸­ä¸€ç§æˆ–è€…ä¸¤ç§geo-referenceæ—¶çš„è¯¯å·®ã€‚


	Read OPENVSLAM code
	å…¼å®¹å¤šç§ç›¸æœºç±»å‹ï¼Œå¹¶å¯ä»¥è½»æ¾å®šåˆ¶å…¼å®¹å…¶ä»–ç±»å‹ç›¸æœºï¼›
	å¯ä»¥å­˜å‚¨å’ŒåŠ è½½åˆ›å»ºçš„åœ°å›¾ï¼Œç„¶åOpenVSLAMå¯ä»¥åŸºäºé¢„å…ˆæ„å»ºçš„åœ°å›¾å®šä½æ–°å›¾åƒï¼›
	ç³»ç»Ÿå®Œå…¨æ¨¡å—åŒ–çš„ï¼›

	å­¦ä¹ æ¦‚ç‡æœºå™¨äººç›¸å…³çŸ¥è¯†ä»¥ä¾¿æ›´æ·±å…¥çš„ç†è§£SLAMæ–‡çŒ®ã€‚


Next week work plan
Continue to build related project environment for SLAM and read OPENVSLAM
Continue to do research on SLAM algorithm

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
Time: from 17/05/2019 to 25/05/2019
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
	Read Paper
Landmark based localization in urban environment
 
	Pose prediction and uncertainty propagation
åœ¨å·²çŸ¥çš„tæ—¶åˆ»çš„Poseä¸ºPt, åˆ™åœ¨t+1æ—¶åˆ»çš„Poseä¸ºï¼š
P_(t+1)^*=P_t+v_t.âˆ†t
æ ¹æ®covariance propagation principle, Vtçš„åæ–¹å·®çŸ©é˜µä¸ºï¼š
âˆ‘_vtâ–’ã€–AÎ£_p A^T ã€—
åˆ™t+1æ—¶åˆ»Poseå¯å†™ä¸ºï¼š
Î£_(p_(t+1))^*=Î£_pt+Î”t^2 Î£_vt
	Guided matching
 
ç”±P_(t+1)^*å’Œtie pointså¾—åˆ°searching areaï¼Œå†ç”± Normalized cross correlation score æ–¹æ³•æ‰¾åˆ°åœ¨t+1å›¾åƒä¸Šçš„xçš„ç²¾å‡†ä½ç½®ã€‚
	Searching new tie points
ä¸ºäº†å¾—åˆ°2D correspondencesï¼Œ å½“æˆ‘ä»¬åœ¨æ–°çš„frameä¸Šæ‰¾åˆ°æ–°çš„ç‰¹å¾ç‚¹æ—¶ï¼Œæˆ‘ä»¬éœ€è¦å†ä¸Šä¸€ä¸ªframeé‡ŒåŒ¹é…å‡ºæ¥ã€‚ä¸ºäº†åœ¨ä¸Šä¸€ä¸ªframe It ä¸­æ‰¾åˆ°åŒ¹é…ç‚¹ï¼Œæˆ‘ä»¬ç”¨ä¹‹å‰çš„æ–¹æ³•Itä¸It+1ä¹‹é—´çš„correspondencesï¼Œ ç„¶åå†ç”±bi-cubic interpolationæ–¹æ³•åœ¨Itä¸­æ‰¾åˆ°æ›¿ä»£åŸæ¥çš„ç‰¹å¾ç‚¹.

Semantic Localization Via the Matrix Permanent
æ–‡ç« åˆ›æ–°ç‚¹ï¼š
1ï¼‰ å°è¯•å»å»ºç«‹è·¯æ ‡ç‚¹å’Œè§‚æµ‹ä¹‹é—´çš„æ‰€æœ‰å¯èƒ½çš„æ¦‚ç‡å…³è”ï¼Œè€Œä¸æ˜¯ä¸€å¯¹ä¸€çš„æ•°æ®å…³è”ã€‚è¿™æ ·çš„å¥½å¤„æ˜¯é¿å…ä¸€å¯¹ä¸€å…³è”ä¸­é”™è¯¯å…³è”çš„å½±å“ã€‚å› ä¸ºåœ¨è¯­ä¹‰SLAMä¸­ï¼Œè¯­ä¹‰ä¿¡æ¯çš„æ•°é‡ç›¸æ¯”äºç‰¹å¾ç‚¹è€Œè¨€æ˜¯ç¨€å°‘çš„ï¼Œå› æ­¤ä¸å½“çš„æ•°æ®å…³è”çš„ä¸ªæ•°åº”å½“å°½å¯èƒ½çš„å°‘ï¼Œå¦åˆ™å¯èƒ½å¯¼è‡´å§¿æ€ä¼°è®¡å¾ˆå¿«å‡ºç°æ¼‚ç§»ã€‚
2ï¼‰è€ƒè™‘äº†ç›®æ ‡è¯†åˆ«ä¸­çš„é”™è¯¯ç‡å’Œæ¼æ£€ç‡ã€‚
3) ä¼˜åŒ–äº†åéªŒæ¦‚ç‡çš„è®¡ç®—æ–¹æ³•ã€‚å»ºç«‹æ•´ä¸ªæ¦‚ç‡åˆ†å¸ƒæ˜¯ä¸€ä¸ªN!N!å¤æ‚åº¦çš„é—®é¢˜ï¼Œä½œè€…å°†å…¶è½¬åŒ–ä¸ºä¸€ä¸ªå¤šé¡¹å¼å¤æ‚åº¦çš„é—®é¢˜

	Build related project environment for SLAM & debug.
	é€‰æ‹©æ•°æ®é›†TUMæ•°æ®é›†
	è°ƒç ”ä¸¤ä¸¤å¸§çš„è¿ç»­çš„è§†è§‰é‡Œç¨‹è®¡çš„å®ç°
ç¬¬ä¸€æ­¥ï¼šå¯¹æ–°æ¥çš„å½“å‰å¸§ï¼Œæå–å…³é”®ç‚¹å’Œæè¿°å­
ç¬¬äºŒæ­¥ï¼šå¦‚æœç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œåˆ™è¯¥å¸§ä¸ºå‚è€ƒå¸§ï¼Œæ ¹æ®æ·±åº¦å›¾è®¡ç®—å…³é”®ç‚¹çš„3Dä½ç½®ï¼Œè¿”å›ä¸Šä¸€æ­¥
ç¬¬ä¸‰æ­¥ï¼šä¼°è®¡å‚è€ƒå¸§å’Œå½“å‰å¸§çš„è¿åŠ¨
ç¬¬å››æ­¥ï¼šåˆ¤æ–­ä¸Šè¿°ä¼°è®¡æ˜¯å¦æˆåŠŸ
ç¬¬äº”æ­¥ï¼šè‹¥æˆåŠŸï¼ŒæŠŠå½“å‰å¸§å½“ä½œæ–°çš„å‚è€ƒå¸§ï¼Œè¿”å›ç¬¬ä¸€æ­¥
ç¬¬å…­æ­¥ï¼šè‹¥å¤±è´¥ï¼Œè®°å½•è¿ç»­ä¸¢å¤±å¸§ã€‚å½“è¿ç»­ä¸¢å¤±è¶…è¿‡ä¸€å®šå¸§æ•°æ—¶ï¼ŒVOå¤±è´¥ï¼Œç®—æ³•ç»“æŸï¼Œè‹¥æœªå¤±è´¥è¿”å›ç¬¬ä¸€æ­¥
	å®ç°Cameraç±»å­˜å‚¨ç›¸æœºçš„å†…å‚å’Œå¤–å‚ï¼Œå¹¶å®Œæˆç›¸æœºåæ ‡ç³»ã€åƒç´ åæ ‡ç³»å’Œä¸–ç•Œåæ ‡ç³»ä¹‹é—´çš„å˜æ¢ã€‚


Next week work plan
Continue to build related project environment for SLAM
Continue to do research on SLAM algorithm

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
Time: from 10/05/2019 to 16/05/2019
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
	Read Paper
Probabilistic Data Association for Semantic SLAM
ä¼ ç»Ÿçš„SLAMç®—æ³•éƒ½ä¾èµ–äºä½çº§åˆ«çš„å‡ ä½•ç‰¹å¾ï¼Œæ¯”å¦‚ç‚¹ã€çº¿å’Œå¹³é¢ã€‚è¿™äº›ç‰¹å¾æ— æ³•å¯¹ç¯å¢ƒä¸­è§‚æµ‹åˆ°çš„æ ‡å¿—ç‰©è¿›è¡Œè¯­ä¹‰æ ‡è¯†ã€‚è€Œä¸”ï¼ŒåŸºäºè¿™äº›ä½çº§ç‰¹å¾ä½¿å¾—å›ç¯æ£€æµ‹é€šå¸¸ä¾èµ–äºæ‘„åƒæœºçš„è§†è§’ï¼Œè€Œä¸”åœ¨æ¨¡ç³Šæˆ–é‡å¤æ€§çš„çº¹ç†ç¯å¢ƒä¸­å®¹æ˜“æ£€æµ‹å¤±è´¥ã€‚å¦ä¸€æ–¹é¢ï¼Œé€šè¿‡ç›®æ ‡è¯†åˆ«å¯ä»¥æ¨æµ‹å‡ºæ ‡å¿—ç‰©ç§ç±»çš„å¤§å°ï¼Œä»è€Œäº§ç”Ÿä¸€å°ç»„æ˜“äºè¯†åˆ«çš„æ ‡å¿—ç‰©ï¼Œéå¸¸é€‚ç”¨äºä¸è§†è§’æ— å…³çš„é—­ç¯æ£€æµ‹ã€‚ç„¶è€Œï¼Œå½“åœ°å›¾ä¸­å­˜åœ¨å¤šä¸ªåŒç±»ç‰©ä½“æ—¶ï¼Œåˆ™éœ€è¦å¯¹å…³é”®çš„æ•°æ®è¿›è¡Œå…³è”ã€‚ä½†æ•°æ®å…³è”å’Œè¯†åˆ«é€šå¸¸æ˜¯ç”¨ç¦»æ•£æ–¹æ³•è§£å†³çš„ç¦»æ•£é—®é¢˜ï¼Œè€Œä¼ ç»ŸSLAMæ˜¯ä¸€ä¸ªå¯¹å°ºåº¦ä¿¡æ¯çš„è¿ç»­ä¼˜åŒ–é—®é¢˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†ä¼ æ„Ÿå™¨çŠ¶æ€å’Œè¯­ä¹‰æ ‡å¿—ç‰©çš„ä½ç½®ä¿¡æ¯å»ºæ¨¡æˆä¸€ä¸ªä¼˜åŒ–é—®é¢˜ï¼Œèåˆäº†å°ºåº¦ä¿¡æ¯ï¼Œè¯­ä¹‰ä¿¡æ¯å’Œæ•°æ®å…³è”ã€‚ç„¶åæŠŠå®ƒåˆ†è§£ä¸ºä¸¤ä¸ªç›¸äº’å…³è”çš„é—®é¢˜ï¼šä¸€ä¸ªæ˜¯ç¦»æ•£æ•°æ®å…³è”å’Œæ ‡å¿—ç‰©ç§ç±»æ¦‚ç‡ä¼°è®¡ï¼Œå¦ä¸€ä¸ªæ˜¯å¯¹å°ºåº¦çŠ¶æ€çš„è¿ç»­ä¼˜åŒ–ã€‚ä¼°è®¡å‡ºçš„æ ‡å¿—ç‰©å’Œæœºå™¨äººå§¿æ€å½±å“ç€æ•°æ®çš„å…³è”å’Œæ ‡å¿—ç‰©ç§ç±»çš„åˆ†å¸ƒï¼Œè€Œè¿™åè¿‡æ¥åˆå½±å“æœºå™¨äºº-æ ‡å¿—ç‰©å§¿æ€çš„ä¼˜åŒ–ã€‚æœ€åï¼Œé€šè¿‡å®¤å†…å’Œå®¤å¤–æ•°æ®é›†éªŒè¯äº†æœ¬æ–‡ç®—æ³•çš„æ€§èƒ½ã€‚


	Use SIFT to finish front-end of SLAM
PNP & FlannBasedMatcher
R is 
[â– (0.87703&-0.36519&0.31217@-0.47609&-0.57344&0.66670@-0.06446&-0.73334&-0.67679)]
t is
[â– (-0.51279@-1.02764@1.60342)]

Next week work plan
Build related project environment for SLAM
Continue to do research on SLAM algorithm

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
Time: from 26/04/2019 to 09/05/2019
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
	Use SIFT to finish front-end of SLAM
æ‰€æœ‰åŒ¹é…å¯¹
 

ä¼˜åŒ–åçš„åŒ¹é…å¯¹
 

ä¸€å…±æ‰¾åˆ°62ç»„åŒ¹é…ç‚¹
2d-2d
Fundamental matrix is 
[â– (0.00262&0.01943&-10.95624@-0.02324&-0.00366&26.35244@9.28720&-23.62500&1)]
Essential matrix is
[â– (-0.00037&-0.18487&-0.05635@0.11797&-0.02496&0.69488@0.03079&-0.68119&-0.01606)]
Homograph matrix is
[â– (0.94435&-0.17971&47.64819@0.03021&0.99887&6.03966@-0.00004&0.00012&1)]
R is 
[â– (0.99464&-0.03199&0.09831@0.02907&0.99097&0.03039@-0.99217&-0.02793&0.99467)]
t is
[â– (-0.96192@-0.07191@0.26370)]

	Use SURF to finish front-end of SLAM
æ‰€æœ‰åŒ¹é…å¯¹
 




ä¼˜åŒ–åçš„åŒ¹é…å¯¹
 
ä¸€å…±æ‰¾åˆ°62ç»„åŒ¹é…ç‚¹
2d-2d
Fundamental matrix is 
[â– (1.71114&5.88490&-0.00197@-4.66375&2.32295&-0.11672@0.00495&0.11024&1)]
Essential matrix is
[â– (0.00809&0.20459&0.03286@-0.15777&0.02660&-0.68822@0.00566&0.67633&0.01669)]
Homograph matrix is
[â– (0.96103&-0.05038&0.06833@0.04860&0.99844&0.02745@-0.00003&0.00014&1)]
R is
[â– (0.99638&-0.05038&0.06833@0.04860&0.99844&0.027458@-0.06961&-0.02403&0.99728)]
t is
[â– (-0.95602@-0.03860@0.29072)]

	Do research on SLAM algorithm
SIFTç®—æ³•åˆ†è§£ä¸ºå¦‚ä¸‹å››æ­¥ï¼š
1. å°ºåº¦ç©ºé—´æå€¼æ£€æµ‹ï¼šæœç´¢æ‰€æœ‰å°ºåº¦ä¸Šçš„å›¾åƒä½ç½®ã€‚é€šè¿‡é«˜æ–¯å¾®åˆ†å‡½æ•°æ¥è¯†åˆ«æ½œåœ¨çš„å¯¹äºå°ºåº¦å’Œæ—‹è½¬ä¸å˜çš„å…´è¶£ç‚¹ã€‚
2. å…³é”®ç‚¹å®šä½ï¼šåœ¨æ¯ä¸ªå€™é€‰çš„ä½ç½®ä¸Šï¼Œé€šè¿‡ä¸€ä¸ªæ‹Ÿåˆç²¾ç»†çš„æ¨¡å‹æ¥ç¡®å®šä½ç½®å’Œå°ºåº¦ã€‚å…³é”®ç‚¹çš„é€‰æ‹©ä¾æ®äºå®ƒä»¬çš„ç¨³å®šç¨‹åº¦ã€‚
3. æ–¹å‘ç¡®å®šï¼šåŸºäºå›¾åƒå±€éƒ¨çš„æ¢¯åº¦æ–¹å‘ï¼Œåˆ†é…ç»™æ¯ä¸ªå…³é”®ç‚¹ä½ç½®ä¸€ä¸ªæˆ–å¤šä¸ªæ–¹å‘ã€‚æ‰€æœ‰åé¢çš„å¯¹å›¾åƒæ•°æ®çš„æ“ä½œéƒ½ç›¸å¯¹äºå…³é”®ç‚¹çš„æ–¹å‘ã€å°ºåº¦å’Œä½ç½®è¿›è¡Œå˜æ¢ï¼Œä»è€Œæä¾›å¯¹äºè¿™äº›å˜æ¢çš„ä¸å˜æ€§ã€‚
4. å…³é”®ç‚¹æè¿°ï¼šåœ¨æ¯ä¸ªå…³é”®ç‚¹å‘¨å›´çš„é‚»åŸŸå†…ï¼Œåœ¨é€‰å®šçš„å°ºåº¦ä¸Šæµ‹é‡å›¾åƒå±€éƒ¨çš„æ¢¯åº¦ã€‚è¿™äº›æ¢¯åº¦è¢«å˜æ¢æˆä¸€ç§è¡¨ç¤ºï¼Œè¿™ç§è¡¨ç¤ºå…è®¸æ¯”è¾ƒå¤§çš„å±€éƒ¨å½¢çŠ¶çš„å˜å½¢å’Œå…‰ç…§å˜åŒ–ã€‚

SURFç®—æ³•åˆ†è§£ä¸ºå¦‚ä¸‹å››æ­¥ï¼š
1. æ„å»ºHessianï¼ˆé»‘å¡çŸ©é˜µï¼‰ï¼Œç”Ÿæˆæ‰€æœ‰çš„å…´è¶£ç‚¹ï¼Œç”¨äºç‰¹å¾çš„æå–
2. æ„å»ºå°ºåº¦ç©ºé—´ï¼šä¸åŒç»„é—´å›¾åƒçš„å°ºå¯¸éƒ½æ˜¯ä¸€è‡´çš„ï¼Œä½†ä¸åŒç»„é—´ä½¿ç”¨çš„ç›’å¼æ»¤æ³¢å™¨çš„æ¨¡æ¿å°ºå¯¸é€æ¸å¢å¤§ï¼ŒåŒä¸€ç»„é—´ä¸åŒå±‚é—´ä½¿ç”¨ç›¸åŒå°ºå¯¸çš„æ»¤æ³¢å™¨ï¼Œä½†æ˜¯æ»¤æ³¢å™¨çš„æ¨¡ç³Šç³»æ•°é€æ¸å¢å¤§ã€‚ 
3. ç‰¹å¾ç‚¹å®šä½ï¼šå°†ç»è¿‡HessiançŸ©é˜µå¤„ç†çš„æ¯ä¸ªåƒç´ ç‚¹ä¸äºŒç»´å›¾åƒç©ºé—´å’Œå°ºåº¦ç©ºé—´é‚»åŸŸå†…çš„26ä¸ªç‚¹è¿›è¡Œæ¯”è¾ƒï¼Œåˆæ­¥å®šä½å‡ºå…³é”®ç‚¹ï¼Œå†ç»è¿‡æ»¤é™¤èƒ½é‡æ¯”è¾ƒå¼±çš„å…³é”®ç‚¹ä»¥åŠé”™è¯¯å®šä½çš„å…³é”®ç‚¹ï¼Œç­›é€‰å‡ºæœ€ç»ˆçš„ç¨³å®šçš„ç‰¹å¾ç‚¹ã€‚ 
4. ç‰¹å¾ç‚¹ä¸»æ–¹å‘åˆ†é…ï¼šé‡‡ç”¨çš„æ˜¯ç»Ÿè®¡ç‰¹å¾ç‚¹åœ†å½¢é‚»åŸŸå†…çš„harrå°æ³¢ç‰¹å¾ã€‚ åœ¨ç‰¹å¾ç‚¹çš„åœ†å½¢é‚»åŸŸå†…ï¼Œç»Ÿè®¡60åº¦æ‰‡å½¢å†…æ‰€æœ‰ç‚¹çš„æ°´å¹³ã€å‚ç›´harrå°æ³¢ç‰¹å¾æ€»å’Œï¼Œç„¶åæ‰‡å½¢ä»¥ä¸€å®šé—´éš”è¿›è¡Œæ—‹è½¬å¹¶å†æ¬¡ç»Ÿè®¡è¯¥åŒºåŸŸå†…harrå°æ³¢ç‰¹å¾å€¼ä¹‹åï¼Œæœ€åå°†å€¼æœ€å¤§çš„é‚£ä¸ªæ‰‡å½¢çš„æ–¹å‘ä½œä¸ºè¯¥ç‰¹å¾ç‚¹çš„ä¸»æ–¹å‘ã€‚ 
5. å…³é”®ç‚¹æè¿°ï¼šSurfåŠ å…¥äº†HessiançŸ©é˜µè¿¹çš„åˆ¤æ–­ï¼Œå¦‚æœä¸¤ä¸ªç‰¹å¾ç‚¹çš„çŸ©é˜µè¿¹æ­£è´Ÿå·ç›¸åŒï¼Œä»£è¡¨è¿™ä¸¤ä¸ªç‰¹å¾å…·æœ‰ç›¸åŒæ–¹å‘ä¸Šçš„å¯¹æ¯”åº¦å˜åŒ–ï¼Œå¦‚æœä¸åŒï¼Œè¯´æ˜è¿™ä¸¤ä¸ªç‰¹å¾ç‚¹çš„å¯¹æ¯”åº¦å˜åŒ–æ–¹å‘æ˜¯ç›¸åçš„ï¼Œå³ä½¿æ¬§æ°è·ç¦»ä¸º0ï¼Œä¹Ÿç›´æ¥äºˆä»¥æ’é™¤ã€‚

	Prepare for mid-exam

Next week work plan
Build related project environment for SLAM
Continue to do research on SLAM algorithm

â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
Time: from 19/04/2019 to 25/04/2019
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

	Continue to finish front-end of SLAM
2d-2d
ä¸€å…±æ‰¾åˆ°äº†79 ç»„åŒ¹é…ç‚¹
Fundamental matrix is
[â– (5.43545&0.00013&-0.02104@-0.00013&2.33947&-0.00633@0.02107&-0.00366&1)]
Essential matrix is
[â– (0.01724&0.32805&0.04737@-0.32432&0.03292&-0.62625@-0.00588&0.62538&-0.01438)]
Homograph matrix is
[â– (0.91317&-0.05339&0.00634@0.02223&0.98260&6.50891@-0.00001&-0.02455&1)]
R is
[â– (0.99855&-0.05339&0.00634@0.05321&0.99827&0.02492@-0.01281&-0.02455&0.99966)]
t is
[â– (-0.88299@-0.05539@0.46610)]

	Debug code &G2O learning
	Prepare for mid-exam
	Next week work plan
Continue to do slam simulation
Continue to do research on semantic segmentation SLAM



________________________________________________________________________________
Time: from 12/04/2019 to 18/04/2019
	Try to finish front-end 
 

 

 
PnP:
ä¸€å…±æ‰¾åˆ°79ç»„åŒ¹é…ç‚¹ï¼Œè½¬ç§»çŸ©é˜µå’Œå¹³ç§»å‘é‡åˆ†åˆ«ä¸ºï¼š
R=[â– (0.99779&-0.05195&0.04125@0.05073&0.99826&0.02995@-0.04273&-0.02779&0.99869)]
t=[â– (-0.64553@-0.05776@0.28446)]
BAä¼˜åŒ–åï¼š
R=[â– (0.99777&-0.05194&0.04177@0.05073&0.99827&0.02958@-0.04224&-0.02739&0.99869)]
t=[â– (-0.64977@-0.05452@0.29556)]

	Paper reading
Landmark based localization in urban environment
Publicationï¼šISPRS Journal of Photogrammetry and Remote Sensing(2018)
æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‘„åƒæœºå’Œå‚è€ƒè·¯æ ‡çš„ä¸ç¡®å®šåº¦åˆ†æçš„è·¯æ ‡å®šä½æ–¹æ³•ã€‚è¯¥ç³»ç»Ÿé€‚ç”¨äºå…­è‡ªç”±åº¦å§¿æ€ä¼°è®¡çš„ä¸åŒæ‘„åƒæœºé…ç½®ã€‚æœ¬æ–‡é‡‡ç”¨å±€éƒ¨BAæ–¹æ³•è¿›è¡Œä¼˜åŒ–ï¼Œå¹¶æ•´åˆå‚è€ƒè·¯æ ‡å‡å°æ¼‚ç§»ï¼Œç‰¹åˆ«è€ƒè™‘äº†ä¸ç¡®å®šåº¦åˆ†æã€‚ä¸€æ–¹é¢ï¼Œæœ¬æ–‡é‡‡ç”¨ä¼°è®¡å§¿æ€çš„ä¸ç¡®å®šæ€§æ¥é¢„æµ‹å®šä½çš„ç²¾åº¦ã€‚å¦ä¸€æ–¹é¢ï¼Œåœ¨åŒ¹é…ã€è·Ÿè¸ªå’Œè·¯æ ‡é…å‡†æ—¶è€ƒè™‘äº†ä¸ç¡®å®šæ€§ä¼ æ’­ã€‚è¯¥æ–¹æ³•åœ¨KITTIæ•°æ®é›†å’Œç§»åŠ¨æµ‹é‡ç³»ç»Ÿè·å–çš„æ•°æ®ä¸Šè¿›è¡Œäº†æµ‹è¯•è¯„ä¼°ã€‚å®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡çš„ç®—æ³•å¯ä»¥è¾¾åˆ°åˆ†ç±³çº§çš„ç²¾åº¦ã€‚
 
ç³»ç»Ÿä¸»è¦åŒ…æ‹¬ä¸‰éƒ¨åˆ†:æ¯ä¸€å¸§çš„åˆå§‹ä½å§¿ä¼°è®¡ã€å…³é”®å¸§çš„é€‰å–å’Œè·¯æ ‡æ•´åˆä¼˜åŒ–ã€‚è¯¥ç³»ç»Ÿä»ä¸€ä¸ªä½æˆæœ¬çš„GPSæä¾›çš„å·²çŸ¥ç‚¹å‡ºå‘ï¼Œè™½ç„¶åˆå§‹ç‚¹ä¸æ˜¯å¾ˆç²¾ç¡®ï¼Œä½†æ˜¯å®ƒçš„çš„ä¸ç¡®å®šæ€§åœ¨åˆå§‹åŒ–ä»ç„¶åä»ç„¶å¯ä»¥ä¼˜åŒ–ã€‚äº‹å®ä¸Šï¼Œè¿™ç§ä¸ç¡®å®šæ€§å¯ä»¥ä¼ æ’­åˆ°è½¨è¿¹ä¸­ï¼Œå¹¶åœ¨æ•´åˆäº†åœ°ç†å‚è€ƒåœ°æ ‡åå¾—åˆ°æ¶ˆé™¤ã€‚

	Other work
Prepare for mid-exam

	Next week work plan
Continue to do slam simulation
Continue to do research on semantic segmentation SLAM
Prepare for mid-exam


â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
Time: from 28/03/2019 to 04/04/2019
1.Paper reading:
Loop Closure Detection for Visual SLAM Systems Using Convolutional Neural Network
Author: Xiwu Zhang
Publication: Proceedings of the 23rd International Conference on Automation & Computing, University of  Huddersfield ,  Huddersfield, UK, 7-8 September 2017
Main idea:
We propose a loop closure detection method based on convolutional neural networks
 
	Normalization: For each feature vector extracted from CNN model, we perform  normalization step as follows:
(v_1,â€¦v_d )â†(v_1/âˆš(âˆ‘_(j=1)^dâ–’v_j^2 ),â€¦v_d/âˆš(âˆ‘_(j=1)^dâ–’v_j^2 ))
	PCA Dimensionality Reduction: Suppose we have obtained normalized feature vectors and the corresponding matrix ğ‘‹ consists of these vectors is:
X=[â– (V^I1@V^I2@â– (â€¦@V^In ))]
a principal component analysis procedure is performed as the following algorithm:
Let V Ì…=1/n âˆ‘_(i=1)^nâ–’V^((Ii)) 
For i=1 to n do
Replace V^((Ii)) in X with V^((Ii))-Â¯V
End for
cov=X^T X
[U,S,W]=svd(cov)
V_reduced^Ii=V^Ii U[:,:500]
	Whitening: they whitened each feature vector according to the form:
V_(whitened,j)^((Ii))=(V_(reduced,j)^((Ii)))/âˆš(Î»_j+Îµ)

	Euclidean distance:
D(i,j)=â€–(V_w^Ii)/â€–V_w^Ii â€–_2 -(V_w^Ij)/â€–V_w^Ij â€–_2 â€–_2
	Similarity score :
S(i,j)=1-(D(i,j))/(maxâ¡{D(i,j)})
If the similarity score is larger than a specific threshold, we regard it as a loop

2. Do research on semantic segmentation SLAM
3. Code reading:
Github.com/gaoxiang12/slambook

Next week work plan
Continue to read Github.com/gaoxiang12/slambook
Continue to do research on semantic segmentation SLAM

















Time: from 21/03/2019 to 27/03/2019
Paper readingï¼š
Robust RGB-D SLAM in Dynamic Environment Using Faster R-CNN
Author: Sifan Yang
Publicationï¼š2017 3rd IEEE International Conference on Computer and Communication
Main idea:
This paper proposed a method which is used in dynamic environment. We first check whether there are objects moving by the threshold which represents consistency of matching and identify every potential candidate of the dynamic object. If the dynamic existence is confirmed, we compute the dynamic region and figure out the dynamic object efficiently. Then we will cull the wrong data association in dynamic region and add more new data association we donâ€™t have in static region..
 
1. Use Faster-RCNN to detect and identify the potential candidate of the dynamic object whose category will be labeled. 
2. Distinguish the stationary from the dynamic environment and refine the data association by removing the mismatching related to the dynamics. 
They compute the consistency of the point J in corresponding object regions.
J=âˆš(1/N âˆ‘_(i=1)^Nâ–’â”œ X_i^h-(R_(h,k) X_i^k+t_(h,k))â”¤â€–^2 )
It means that we project the feature points in the stationary region of the current frame k into the corresponding region of the keyframe h with the estimated camera pose T_(h,k). Then they compute the similarity between these. If the J is over the threshold, they label the region of object as dynamic status from stationary status and update the data association by filtering out the data associations in the moving region. Once the status is dynamic, thereâ€™s no chance for status to turn back. If the J is within the threshold, they label the region as stationary state and reserve previous data association.
3. Estimate the camera pose with better data association and the optimization of the graph. 
4. With accurate pose estimation, they reconstruct the dynamic environment successfully.

å…³äºè¯­ä¹‰åˆ†å‰²çš„SLAMçš„è°ƒç ”æ„Ÿæ‚Ÿ
SLAMçš„å¦ä¸€ä¸ªå¤§æ–¹å‘å°±æ˜¯å’Œæ·±åº¦å­¦ä¹ æŠ€æœ¯ç»“åˆã€‚åˆ°ç›®å‰ä¸ºæ­¢ï¼ŒSLAMçš„æ–¹æ¡ˆéƒ½å¤„äºç‰¹å¾ç‚¹æˆ–è€…åƒç´ çš„å±‚çº§ã€‚å…³äºè¿™äº›ç‰¹å¾ç‚¹æˆ–åƒç´ åˆ°åº•æ¥è‡ªäºä»€ä¹ˆä¸œè¥¿ï¼Œæˆ‘ä»¬ä¸€æ— æ‰€çŸ¥ã€‚è¿™ä½¿å¾—è®¡ç®—æœºè§†è§‰ä¸­çš„SLAMä¸æˆ‘ä»¬äººç±»çš„åšæ³•ä¸æ€ä¹ˆç›¸ä¼¼ï¼Œè‡³å°‘æˆ‘ä»¬è‡ªå·±ä»æ¥çœ‹ä¸åˆ°ç‰¹å¾ç‚¹ï¼Œä¹Ÿä¸ä¼šå»æ ¹æ®ç‰¹å¾ç‚¹åˆ¤æ–­è‡ªèº«çš„è¿åŠ¨æ–¹å‘ã€‚ æˆ‘ä»¬çœ‹åˆ°çš„æ˜¯ä¸€ä¸ªä¸ªç‰©ä½“ï¼Œé€šè¿‡å·¦å³çœ¼åˆ¤æ–­å®ƒä»¬çš„è¿œè¿‘ï¼Œç„¶ååŸºäºå®ƒä»¬åœ¨å›¾åƒå½“ä¸­çš„è¿åŠ¨æ¨æµ‹ç›¸æœºçš„ç§»åŠ¨ã€‚ä¹‹å‰ï¼Œç ”ç©¶è€…å°±è¯•å›¾å°†ç‰©ä½“ä¿¡æ¯ç»“åˆåˆ°SLAMä¸­ï¼Œæ›¾æŠŠç‰©ä½“è¯†åˆ«ä¸è§†è§‰SLAMç»“åˆèµ·æ¥ï¼Œæ„å»ºå¸¦ç‰©ä½“æ ‡ç­¾çš„åœ°å›¾ã€‚å¦å¤–ï¼ŒæŠŠæ ‡ç­¾ä¿¡æ¯å¼•å…¥åˆ°BAæˆ–ä¼˜åŒ–ç«¯çš„ç›®æ ‡å‡½æ•°å’Œçº¦æŸä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ç»“åˆç‰¹å¾ç‚¹çš„ä½ç½®ä¸æ ‡ç­¾ä¿¡æ¯è¿›è¡Œä¼˜åŒ–ã€‚è¯­ä¹‰ä¿¡æ¯å¯ä»¥å¸®åŠ©SLAMæé«˜å»ºå›¾å’Œå®šä½çš„ç²¾åº¦ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¤æ‚çš„åŠ¨æ€åœºæ™¯ã€‚ä¼ ç»ŸSLAMçš„å»ºå›¾å’Œå®šä½å¤šæ˜¯åŸºäºåƒç´ çº§åˆ«çš„å‡ ä½•åŒ¹é…ã€‚å€ŸåŠ©è¯­ä¹‰ä¿¡æ¯ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ•°æ®å…³è”ä»ä¼ ç»Ÿçš„åƒç´ çº§åˆ«å‡çº§åˆ°ç‰©ä½“çº§åˆ«ï¼Œæå‡å¤æ‚åœºæ™¯ä¸‹çš„ç²¾åº¦ã€‚å€ŸåŠ©SLAMæŠ€æœ¯è®¡ç®—å‡ºç‰©ä½“ä¹‹é—´çš„ä½ç½®çº¦æŸï¼Œå¯ä»¥å¯¹åŒä¸€ç‰©ä½“åœ¨ä¸åŒè§’åº¦ã€‚ä¸åŒæ—¶åˆ»çš„è¯†åˆ«ç»“æœè¿›è¡Œä¸€è‡´æ€§çº¦æŸï¼Œä»è€Œæé«˜è¯­ä¹‰ç†è§£çš„ç²¾åº¦ã€‚ ç»¼åˆæ¥è¯´ï¼ŒSLAMå’Œè¯­ä¹‰çš„ç»“åˆç‚¹ä¸»è¦æ˜¯ä»¥ä¸‹æ–¹é¢ï¼š
     ä¼ ç»Ÿçš„ç‰©ä½“è¯†åˆ«ã€åˆ†å‰²ç®—æ³•å¾€å¾€åªè€ƒè™‘ä¸€å¹…å›¾ï¼Œè€Œåœ¨SLAMä¸­æˆ‘ä»¬æ‹¥æœ‰ä¸€å°ç§»åŠ¨çš„ç›¸æœºã€‚å¦‚æœæˆ‘ä»¬æŠŠè¿åŠ¨è¿‡ç¨‹ä¸­çš„å›¾ç‰‡éƒ½å¸¦ä¸Šç‰©ä½“æ ‡ç­¾ï¼Œå°±èƒ½å¾—åˆ°ä¸€ä¸ªå¸¦æœ‰æ ‡ç­¾çš„åœ°å›¾ã€‚å¦å¤–ï¼Œç‰©ä½“ä¿¡æ¯äº¦å¯ä¸ºå›ç¯æ£€æµ‹ã€BAä¼˜åŒ–å¸¦æ¥æ›´å¤šçš„æ¡ä»¶ã€‚
 

Code reading:
Github.com/gaoxiang12/slambook

Next week work plan
Continue to read Github.com/gaoxiang12/slambook
Read paper: CNN&SLAM

â€ƒ
Time: from 13/03/2019 to 20/03/2019
Paper readingï¼š
CNN-SLAM: Real-time dense monocular SLAM with learned depth prediction
Authorï¼šKeisuke Tatento 
Publication: CVPR2017

Main idea:
This paper investigates how predicted depth maps from a deep neural network can be deployed for accurate and dense monocular reconstruction. 
Framework
The flow diagram in Fig. 1 sketches the pipeline of the framework. Authors employ a key-frame based SLAM paradigm. Within such approach, a subset of visually distinct frames is collected as key-frames, whose pose is subject to global refinement based on pose graph optimization. At the same time, camera pose estimation is carried out at each input frame, by estimating the transformation between the frame and its nearest key-frame. To maintain a high frame-rate, they propose to predict a depth map via CNN only on key-frames. In particular, if the currently estimated pose is far from that of existing keyframes, a new key-frame is created out of the current frame and its depth estimated via CNN.
 

CNN model for SLAM
The depth prediction architecture is based on ResNet50 and initialized with pre-trained weights on ImageNet. Pooling and FC are replaced by a sequence of residual up-sampling blocks composed of a combination of unpooling and convolutional layers. After up-pooling, drop-out is applied. The loss function is based on the reverse Huber function.
They also retrained this network for predicting pixel-wise semantic labels for RGB images. In this way, they modified the network so that it has as many output channels as the number of categories and employed a soft-max layer and a cross-entropy loss function to be minimized via back-propagation and SGD.
Key-frame Creation & Pose Graph Optimization
There is a problem that sensors for SLAM have different intrinsic parameters from those used to capture the training set, the results will be inaccurate. In this way, they propose to adjust the depth regressed via CNN with the ratio between the focal length of current camera, f_cur and that of the sensor used for training, f_tr  as
D_(k_i ) (u)=f_cur/f_tr  D_(k_i)^~ (u)
Where D_(k_i)^~ is the depth map directly regressed by CNN
This transformation is estimated by minimizing the photometric residual between the intensity image I_t of the current frame and the intensity image I_(k_i ) of the nearest key-frame k_i via weighted Gauss-Newton optimization based on the objective function
E(T_t^(k_i ) )-âˆ‘_(u ÌƒâˆˆÎ©)â–’ã€–Ï((r(u Ìƒ,T_t^(k_i )))/(Ïƒ(r((u,) ÌƒT_t^(k_i )))))ã€—
Where Ïis Huber norm and Ïƒ is a function measuring the residual uncertainty. And r is the photometric residual defined as 
r(u Ìƒ,T_t^(k_i ) )=I_ki (u Ìƒ )-I_t (Ï€(KT_t^ki (V_ki ) Ìƒ(u Ìƒ)))
while V_ki (u) represents a 3D element of the vertex map computed from the key-frameâ€™s depth map
V_ki (u)=K^(-1) u Ì‡D_ki (u)
Once T_t^ki is obtained, the current camera pose in the world coordinate system is computed as 
T_t=T_t^ki T_ki

ä½œè€…é¦–å…ˆç­›é€‰å‡ºå…³é”®å¸§ï¼Œåœ¨å…³é”®å¸§ä¸Šç”¨è®­ç»ƒå¥½çš„CNNç½‘ç»œæ¥é¢„æµ‹å•å¸§å›¾æ·±åº¦å€¼å¾—åˆ°æ·±åº¦å›¾ï¼Œå¹¶ä»¥æ­¤æ·±åº¦å›¾ä½œä¸ºSLAMæ¶æ„å…ˆéªŒæ·±åº¦ã€‚åŒæ—¶åœ¨å…³é”®å¸§ä¸Šç”¨è®­ç»ƒå¥½çš„å¦ä¸€ä¸ªCNNç½‘ç»œæ¥åšè¯­ä¹‰åˆ†å‰²ã€‚
éšååƒç›´æ¥æ³•SLAMçš„ä¸€æ ·åšBAï¼Œç”¨é«˜æ–¯ç‰›é¡¿æ³•ï¼ŒåŸºäºpose graphæ–¹æ³•ä¼˜åŒ–å¾—åˆ°poseï¼Œå’Œæ™®é€šçš„åŠç¨ å¯† SLAMè¿‡ç¨‹åŸºæœ¬ä¸€æ ·ã€‚
å°†æ·±åº¦å›¾å’Œè¯­ä¹‰åˆ†å‰²å›¾èåˆè¿›å…¨å±€å·²æœ‰çš„åœºæ™¯æ·±åº¦å›¾ï¼ˆå®é™…ä¸Šæ˜¯ä¸‰ç»´åœ°å›¾ç‚¹é›†åˆäº†ï¼‰å’Œä¸‰ç»´è¯­ä¹‰åˆ†å‰²å›¾ä¸­


Code reading:
Github.com/gaoxiang12/slambook

Next week work plan
Continue to read Github.com/gaoxiang12/slambook
Read paper: Fully Convolutional Networks for Semantic Segmentation
